{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "357dfc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data_perterbers\t\t\t    ParlAI\r\n",
      "'Exploratory Data Analysis.ipynb'\t    raw_data\r\n",
      "'HAP Filter.ipynb'\t\t\t    ResponsibleNLP\r\n",
      " logs\t\t\t\t\t    results\r\n",
      " nltk_data\t\t\t\t    style-transfer-paraphrase\r\n",
      "'PANDA Copy1.ipynb'\t\t\t    test_trainer\r\n",
      "'PANDA Data Perturber on HAP-Copy1.ipynb'   value\r\n",
      "'PANDA Data Perturber on HAP.ipynb'\t   'VALUE implementation on HAP.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbd16492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'value' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/SALT-NLP/value.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59fa20fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'style-transfer-paraphrase' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/martiansideofthemoon/style-transfer-paraphrase.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8a38158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data_perterbers\r\n",
      "'Exploratory Data Analysis.ipynb'\r\n",
      "'HAP Filter.ipynb'\r\n",
      " nltk_data\r\n",
      " raw_data\r\n",
      " style-transfer-paraphrase\r\n",
      " value\r\n",
      "'VALUE and PANDA implementation on HAP.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "!cd style-transfer-paraphrase\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1357bcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: The conda.compat module is deprecated and will be removed in a future release.\n",
      "Collecting package metadata: done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.6.11\n",
      "  latest version: 23.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /u/camilleh/.conda/envs/value\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.7\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    openssl-1.1.1u             |       h7f8727e_0         3.8 MB\n",
      "    pip-22.3.1                 |   py37h06a4308_0         2.7 MB\n",
      "    python-3.7.13              |       h12debd9_0        53.5 MB\n",
      "    setuptools-65.6.3          |   py37h06a4308_0         1.4 MB\n",
      "    wheel-0.38.4               |   py37h06a4308_0          57 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        61.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
      "  ca-certificates    pkgs/main/linux-64::ca-certificates-2023.05.30-h06a4308_0\n",
      "  certifi            pkgs/main/linux-64::certifi-2022.12.7-py37h06a4308_0\n",
      "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1\n",
      "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
      "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
      "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
      "  ncurses            pkgs/main/linux-64::ncurses-6.3-h7f8727e_2\n",
      "  openssl            pkgs/main/linux-64::openssl-1.1.1u-h7f8727e_0\n",
      "  pip                pkgs/main/linux-64::pip-22.3.1-py37h06a4308_0\n",
      "  python             pkgs/main/linux-64::python-3.7.13-h12debd9_0\n",
      "  readline           pkgs/main/linux-64::readline-8.1.2-h7f8727e_1\n",
      "  setuptools         pkgs/main/linux-64::setuptools-65.6.3-py37h06a4308_0\n",
      "  sqlite             pkgs/main/linux-64::sqlite-3.38.5-hc218d9a_0\n",
      "  tk                 pkgs/main/linux-64::tk-8.6.12-h1ccaba5_0\n",
      "  wheel              pkgs/main/linux-64::wheel-0.38.4-py37h06a4308_0\n",
      "  xz                 pkgs/main/linux-64::xz-5.2.5-h7f8727e_1\n",
      "  zlib               pkgs/main/linux-64::zlib-1.2.12-h7f8727e_2\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? ^C\n",
      "\n",
      "CondaSystemExit: \n",
      "Operation aborted.  Exiting.\n",
      "\n",
      "/bin/bash: y: command not found\n"
     ]
    }
   ],
   "source": [
    "!conda create --name value python=3.7\n",
    "!y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37d740fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c682bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1caed93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk==3.5\n",
      "  Using cached nltk-3.5.zip (1.4 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numpy==1.19.2\n",
      "  Using cached numpy-1.19.2-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting pandas==1.1.3\n",
      "  Using cached pandas-1.1.3-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
      "Collecting tqdm==4.50.2\n",
      "  Using cached tqdm-4.50.2-py2.py3-none-any.whl (70 kB)\n",
      "Collecting neuralcoref==4.0\n",
      "  Using cached neuralcoref-4.0-cp37-cp37m-manylinux1_x86_64.whl (286 kB)\n",
      "Collecting lemminflect==0.2.2\n",
      "  Using cached lemminflect-0.2.2-py3-none-any.whl (769 kB)\n",
      "Collecting spacy==2.1.0\n",
      "  Using cached spacy-2.1.0-cp37-cp37m-manylinux1_x86_64.whl (27.7 MB)\n",
      "Collecting inflect==5.5.2\n",
      "  Using cached inflect-5.5.2-py3-none-any.whl (33 kB)\n",
      "Collecting torch==1.7.1\n",
      "  Using cached torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
      "Collecting transformers==4.16.2\n",
      "  Using cached transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
      "Collecting datasets==2.1.0\n",
      "  Using cached datasets-2.1.0-py3-none-any.whl (325 kB)\n",
      "Collecting click\n",
      "  Downloading click-8.1.4-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib\n",
      "  Using cached joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "Collecting regex\n",
      "  Using cached regex-2023.6.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (755 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./.conda/envs/value/lib/python3.7/site-packages (from pandas==1.1.3->-r value/requirements.txt (line 3)) (2.8.2)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.28.2-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests<3.0.0,>=2.13.0\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting jsonschema<3.0.0,>=2.6.0\n",
      "  Using cached jsonschema-2.6.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.9-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting plac<1.0.0,>=0.9.6\n",
      "  Using cached plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
      "Collecting thinc<7.1.0,>=7.0.2\n",
      "  Using cached thinc-7.0.8-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
      "Collecting preshed<2.1.0,>=2.0.1\n",
      "  Using cached preshed-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (82 kB)\n",
      "Collecting srsly<1.1.0,>=0.0.5\n",
      "  Using cached srsly-1.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
      "Collecting blis<0.3.0,>=0.2.2\n",
      "  Using cached blis-0.2.4-cp37-cp37m-manylinux1_x86_64.whl (3.2 MB)\n",
      "Collecting wasabi<1.1.0,>=0.0.12\n",
      "  Using cached wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/envs/value/lib/python3.7/site-packages (from torch==1.7.1->-r value/requirements.txt (line 9)) (4.6.3)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.53.tar.gz (880 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Collecting tokenizers!=0.11.3,>=0.10.1\n",
      "  Using cached tokenizers-0.13.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/envs/value/lib/python3.7/site-packages (from transformers==4.16.2->-r value/requirements.txt (line 10)) (23.1)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in ./.conda/envs/value/lib/python3.7/site-packages (from transformers==4.16.2->-r value/requirements.txt (line 10)) (6.7.0)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (948 kB)\n",
      "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of inflect to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of spacy to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of lemminflect to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of neuralcoref to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of tqdm to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of numpy to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nltk to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Cannot install -r value/requirements.txt (line 1), -r value/requirements.txt (line 10), -r value/requirements.txt (line 11) and tqdm==4.50.2 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "The conflict is caused by:\n",
      "    The user requested tqdm==4.50.2\n",
      "    nltk 3.5 depends on tqdm\n",
      "    transformers 4.16.2 depends on tqdm>=4.27\n",
      "    datasets 2.1.0 depends on tqdm>=4.62.1\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n",
      "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r 'value/requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "163dafc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"style-transfer-paraphrase/style_paraphrase/inference_utils.py\", line 8, in <module>\r\n",
      "    from style_paraphrase.dataset_config import DATASET_CONFIG, BASE_CONFIG\r\n",
      "ModuleNotFoundError: No module named 'style_paraphrase'\r\n"
     ]
    }
   ],
   "source": [
    "!python 'style-transfer-paraphrase/style_paraphrase/inference_utils.py'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7730bad4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'style_paraphrase'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstyle_paraphrase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2Generator\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'style_paraphrase'"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2d1568d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/u/camilleh/.conda/envs/t4j/bin/python: No module named spacy\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5194d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac8f5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_200_train = pd.read_json('raw_data/commercial-use-allowed/en/toxic200_en/train.json')\n",
    "t200_train = pd.json_normalize(toxic_200_train['data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c46bf8ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GPT2Generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m paraphraser \u001b[38;5;241m=\u001b[39m \u001b[43mGPT2Generator\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpretrained_style_transfer/models/paraphraser_gpt2_large/\u001b[39m\u001b[38;5;124m'\u001b[39m, upper_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m paraphraser\u001b[38;5;241m.\u001b[39mmodify_p(top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m)\n\u001b[1;32m      3\u001b[0m sae_to_aave \u001b[38;5;241m=\u001b[39m GPT2Generator(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpretrained_style_transfer/models/cds_models/aae\u001b[39m\u001b[38;5;124m'\u001b[39m, upper_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GPT2Generator' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "paraphraser = GPT2Generator('pretrained_style_transfer/models/paraphraser_gpt2_large/', upper_length=\"same_5\")\n",
    "paraphraser.modify_p(top_p=0.6)\n",
    "sae_to_aave = GPT2Generator('pretrained_style_transfer/models/cds_models/aae', upper_length=\"same_5\")\n",
    "sae_to_aave.modify_p(top_p=0.6)\n",
    "\n",
    "df = t200_train # FILL THIS PATH IN\n",
    "converted = []\n",
    "batch_size = 32\n",
    "for i in range(int(len(df)/batch_size)+1):\n",
    "    sub_df = df.iloc[batch_size*(i):batch_size*(i+1)].copy()\n",
    "    for col in df.columns:\n",
    "        if (('text' in col) or ('question' in col)) and ('parse' not in col):\n",
    "            sub_df = sub_df[[type(c)==str for c in sub_df[col].values]].copy()\n",
    "            consider = sub_df[col].values\n",
    "            para, prob = paraphraser.generate_batch(consider)\n",
    "            aave, prob = sae_to_aave.generate_batch(para)\n",
    "            sub_df[col+'-glue'] = consider\n",
    "            sub_df[col] = aave\n",
    "            converted.append(sub_df)\n",
    "            \n",
    "converted_df = pd.concat(converted)\n",
    "converted_df.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480667c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
